{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, Row, DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructField, StructType, BooleanType, StringType, DoubleType, IntegerType, ArrayType\n",
    "\n",
    "from stpm.visualization import plot_pattern\n",
    "from stpm.statistics import sum_delta_distrib, compute_mean_delta, count_delta_diff_from_zero, count_n_elements\n",
    "from collections import defaultdict\n",
    "\n",
    "from typing import List, Union, Dict, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r stpm.zip stpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pending-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.addPyFile('stpm.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exempt-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(s: str) -> List[List[str]]:\n",
    "    res = []\n",
    "    stack = []\n",
    "    accumulator = []\n",
    "    str_acc = ''\n",
    "    for c in s:\n",
    "        if c == '[':\n",
    "            stack.append(c)\n",
    "        elif c == ']':\n",
    "            stack.pop()\n",
    "            if len(stack) > 0:\n",
    "                if len(str_acc) > 0:\n",
    "                    accumulator.append(str_acc)\n",
    "                    str_acc = ''\n",
    "                res.append(accumulator)\n",
    "                accumulator = []\n",
    "        elif c == ',':\n",
    "            if len(str_acc) > 0:\n",
    "                accumulator.append(str_acc)\n",
    "                str_acc = ''\n",
    "        elif c == ' ':\n",
    "            continue\n",
    "        else:\n",
    "            str_acc += c\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "personalized-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = spark.udf.register('seqparser', split, ArrayType(ArrayType(StringType())))\n",
    "filter_center = spark.udf.register('filter_center', lambda it: any('S0_T0' in x for x in it[0]), 'boolean')\n",
    "\n",
    "def load_files(paths: List[str], filter_data: bool=True) -> List[DataFrame]:\n",
    "    res = []\n",
    "    schema = StructType([\n",
    "        StructField('freq', IntegerType()),\n",
    "        StructField('relFreq', DoubleType()),\n",
    "        StructField('confidence', DoubleType()),\n",
    "        StructField('sequence', StringType())\n",
    "    ])\n",
    "    for f in paths:\n",
    "        df = spark.read.csv(f, header=None, inferSchema=False, schema=schema) \\\n",
    "                        .withColumn('sequence', splitter(F.col('sequence')))\n",
    "        if filter_data:\n",
    "            df = df.filter('filter_center(sequence)')\n",
    "        res.append(df)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "geographic-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = 'datasets/ShortLongTermTrafficIncidents/patterns_REVISED/'\n",
    "files = [\n",
    "#     'patterns_global.csv',\n",
    "#     'patterns_nyc.csv',\n",
    "    'patterns_boston.csv',\n",
    "#     'patterns_la.csv'\n",
    "]\n",
    "\n",
    "fullpaths = [basepath + x for x in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "valuable-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = load_files(fullpaths, filter_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "undefined-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_df = dfs[0].toPandas()\n",
    "local_df.sort_values('relFreq', ascending=False).to_csv('patterns_boston.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "desperate-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nrules_table(file_list: List[str], df_list: List[DataFrame]) -> pd.DataFrame:\n",
    "    res_dict = {'filename': [], 'count':[]}\n",
    "    for f, df in zip(file_list, df_list):\n",
    "        c = df.count()\n",
    "        print(f'{f} - Number of rules: {c}')\n",
    "        res_dict['filename'].append(f)\n",
    "        res_dict['count'].append(c)\n",
    "        \n",
    "    return pd.DataFrame(res_dict)\n",
    "\n",
    "def compute_statistics(file_list: List[str], df_list: List[DataFrame]) -> pd.DataFrame:\n",
    "    res_dict = defaultdict(list)\n",
    "    for f, df in zip(file_list, df_list):\n",
    "        df = df.cache()\n",
    "        mean_n_elements = df.rdd.map(lambda it: count_n_elements(it['sequence'])).mean()\n",
    "        mean_spatial_delta = compute_mean_delta(df, delta_type='spatial')\n",
    "        mean_temporal_delta = compute_mean_delta(df, delta_type='temporal')\n",
    "        npatterns_spat_delta_gt0 = df.rdd.filter(lambda it: count_delta_diff_from_zero(it['sequence'], delta_type='spatial') > 0).count()\n",
    "        npatterns_temp_delta_gt0 = df.rdd.filter(lambda it: count_delta_diff_from_zero(it['sequence'], delta_type='temporal') > 0).count()\n",
    "        npatterns_both_delta_gt0 = df.rdd.filter(lambda it: count_delta_diff_from_zero(it['sequence'], delta_type='both') > 0).count()\n",
    "        df = df.unpersist()\n",
    "        \n",
    "        res_dict['files'].append(f)\n",
    "        res_dict['tot_patterns'].append(df.count())\n",
    "        res_dict['mean_num_el'].append(mean_n_elements)\n",
    "        res_dict['mean_spat_delta'].append(mean_spatial_delta)\n",
    "        res_dict['mean_temp_delta'].append(mean_temporal_delta)\n",
    "        res_dict['patterns_spat_delta_gt0'].append(npatterns_spat_delta_gt0)\n",
    "        res_dict['patterns_temp_delta_gt0'].append(npatterns_temp_delta_gt0)\n",
    "        res_dict['patterns_both_delta_gt0'].append(npatterns_both_delta_gt0)\n",
    "        \n",
    "        print('#' * 50)\n",
    "        print(f)\n",
    "        print(f'total patterns: {df.count()}')\n",
    "        print(f'mean number of elements: {mean_n_elements}')\n",
    "        print(f'mean spatial delta: {mean_spatial_delta}')\n",
    "        print(f'mean temporal delta: {mean_temporal_delta}')\n",
    "        print(f'number of patterns with at least one element with spatial delta > 0: {npatterns_spat_delta_gt0} ({npatterns_spat_delta_gt0/df.count()})')\n",
    "        print(f'number of patterns with at least one element with temporal delta > 0: {npatterns_temp_delta_gt0} ({npatterns_temp_delta_gt0/df.count()})')\n",
    "        print(f'number of patterns with at least one element with spatial AND temporal delta > 0: {npatterns_both_delta_gt0} ({npatterns_both_delta_gt0/df.count()})')\n",
    "        \n",
    "    return pd.DataFrame(dict(res_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrules_table = generate_nrules_table(files, dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_statistics(files, dfs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Yarn)",
   "language": "python",
   "name": "pyspark_yarn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
